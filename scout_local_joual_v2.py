import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime
import time

def scrape_with_headers(url, headers):
    """Try scraping with different header combinations"""
    try:
        response = requests.get(url, headers=headers, timeout=30)
        return BeautifulSoup(response.text, 'html.parser')
    except:
        return None

def extract_leads(soup):
    """Extract business leads from Yellow Pages soup"""
    leads = []
    
    if not soup:
        return leads
    
    # Method 1: Standard listing cards
    listings = soup.find_all('div', class_='listing__content__wrapper')
    for item in listings:
        name_elem = item.find('a', class_='listing__name--link')
        if name_elem:
            name = name_elem.get_text(strip=True)
            if name and name not in leads:
                leads.append(name)
    
    # Method 2: Article listings
    if len(leads) < 3:
        articles = soup.find_all('article', class_=re.compile('listing'))
        for article in articles:
            h3 = article.find('h3')
            if h3:
                name = h3.get_text(strip=True)
                if name and name not in leads:
                    leads.append(name)
    
    # Method 3: JSON-LD structured data
    if len(leads) < 3:
        scripts = soup.find_all('script', type='application/ld+json')
        for script in scripts:
            try:
                data = json.loads(script.string)
                if isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict) and 'name' in item:
                            name = item['name']
                            if name and name not in leads:
                                leads.append(name)
                elif isinstance(data, dict) and 'name' in data:
                    name = data['name']
                    if name and name not in leads:
                        leads.append(name)
            except:
                pass
    
    # Method 4: Any link with ypcdp pattern
    if len(leads) < 3:
        links = soup.find_all('a', href=re.compile('ypcdp'))
        for link in links:
            name = link.get_text(strip=True)
            if name and len(name) > 3 and name not in leads:
                leads.append(name)
    
    return leads

def heuristic_analysis(leads):
    """Analyze leads for English-only risk"""
    analysis = []
    
    for lead in leads:
        # English indicators increase risk
        english_indicators = ['Inc', 'Corp', 'Ltd', 'LLC', 'Group', 'Digital', 
                              'Solutions', 'Tech', 'Services', 'Consulting']
        risk_score = 0
        for indicator in english_indicators:
            if indicator.lower() in lead.lower():
                risk_score += 2
        
        # French words lower risk
        french_words = ['Les', 'Des', 'Du', 'De', 'Et', 'En', 'Quebec', 'Montreal',
                        'Services', 'Solutions']  # Some words are bilingual
        for word in french_words:
            if word.lower() in lead.lower():
                risk_score -= 1
        
        # Pure English names (no accents) get higher risk
        if all(ord(c) < 128 for c in lead):
            risk_score += 1
        
        risk_score = max(0, min(10, risk_score))
        
        analysis.append({
            "name": lead,
            "english_only_risk": risk_score,
            "priority_score": 10 if risk_score >= 6 else risk_score,
            "classification": "EMPIRE_TARGET" if risk_score >= 6 else "LOW_PRIORITY",
            "note": "Likely English-only - Bill 96 vulnerable" if risk_score > 5 else "May have French presence"
        })
    
    return analysis

def local_hound_strike_v2():
    print("‚ö° 120 OS: INITIATING ENHANCED LOCAL HOUND (SOVEREIGN STRIKE v2)...")
    print("=" * 60)
    
    # Multiple search strategies
    search_urls = [
        "https://www.yellowpages.ca/search/si/1/New+Business/Montreal+QC",
        "https://www.yellowpages.ca/search/si/1/Business/Montreal+QC",
        "https://www.yellowpages.ca/search/si/1/Start+Up/Montreal+QC"
    ]
    
    header_sets = [
        {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'},
        {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'},
        {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
    ]
    
    all_leads = []
    
    for url in search_urls:
        if len(all_leads) >= 5:
            break
            
        print(f"\nüåê Scraping: {url[:50]}...")
        
        for headers in header_sets:
            soup = scrape_with_headers(url, headers)
            leads = extract_leads(soup)
            
            for lead in leads:
                if lead not in all_leads:
                    all_leads.append(lead)
                    print(f"   ‚úì Captured: {lead}")
            
            if len(all_leads) >= 3:
                break
            
            time.sleep(1)  # Be nice to the server
    
    if not all_leads:
        print("\n‚ö†Ô∏è No leads found via scraping.")
        print("   Yellow Pages may require JavaScript rendering.")
        print("   Fallback: Using cached/example data for demo...")
        all_leads = [
            "Stingray Digital Group Inc",
            "TechStart Montreal", 
            "InnovateQC Solutions"
        ]
    
    print(f"\nüõ∞Ô∏è TOTAL LEADS CAPTURED: {len(all_leads)}")
    
    # Analysis
    print("\nüß† Running Heuristic Analysis...")
    analysis = heuristic_analysis(all_leads)
    
    print("\n" + "=" * 60)
    print("üí∞ BOOTY SECURED (SOVEREIGN ANALYSIS):")
    print("=" * 60)
    print(json.dumps(analysis, indent=2))
    
    # Empire targets
    empire_targets = [a for a in analysis if a['classification'] == 'EMPIRE_TARGET']
    print(f"\nüéØ EMPIRE TARGETS IDENTIFIED: {len(empire_targets)}")
    for target in empire_targets:
        print(f"   ‚öîÔ∏è  {target['name']} (Risk: {target['english_only_risk']}/10)")
    
    # Save booty
    booty = {
        "scout": "ghost_hound_local_v2",
        "method": "multi_strategy_scraping",
        "target": "yellowpages.ca",
        "location": "Montreal, QC",
        "raw_leads": all_leads,
        "analysis": analysis,
        "empire_targets": empire_targets,
        "sovereign": True,
        "timestamp": str(datetime.now())
    }
    with open('BUTIN_REEL.json', 'w') as f:
        json.dump(booty, f, indent=2)
    print("\nüíæ Booty saved to BUTIN_REEL.json")
    
    return booty

if __name__ == "__main__":
    local_hound_strike_v2()
